"""
M√≥dulo de gesti√≥n optimizada de duplicados con cach√©
"""
import os
import json
from datetime import datetime, timedelta

CACHE_FILE = "duplicates_check_cache.json"
CACHE_DURATION_HOURS = 24  # Ejecutar limpieza solo una vez al d√≠a

def should_run_duplicate_check():
    """
    Verifica si debe ejecutarse la verificaci√≥n de duplicados bas√°ndose en cach√©.
    Retorna True si debe ejecutarse, False si ya se ejecut√≥ recientemente.
    """
    if not os.path.exists(CACHE_FILE):
        return True
    
    try:
        with open(CACHE_FILE, 'r') as f:
            cache_data = json.load(f)
        
        last_run = datetime.fromisoformat(cache_data.get('last_run', '2000-01-01'))
        now = datetime.now()
        
        # Ejecutar solo si han pasado m√°s de CACHE_DURATION_HOURS
        if now - last_run > timedelta(hours=CACHE_DURATION_HOURS):
            return True
        
        return False
        
    except Exception as e:
        print(f"Error leyendo cach√© de duplicados: {e}")
        return True

def update_duplicate_check_cache():
    """Actualiza el cach√© con la fecha/hora de √∫ltima ejecuci√≥n."""
    try:
        cache_data = {
            'last_run': datetime.now().isoformat(),
            'version': '1.0'
        }
        with open(CACHE_FILE, 'w') as f:
            json.dump(cache_data, f, indent=2)
        
        print(f"‚úÖ Cach√© de verificaci√≥n de duplicados actualizado")
        
    except Exception as e:
        print(f"‚ö†Ô∏è Error actualizando cach√©: {e}")

def force_duplicate_check():
    """Fuerza la ejecuci√≥n de la verificaci√≥n eliminando el cach√©."""
    try:
        if os.path.exists(CACHE_FILE):
            os.remove(CACHE_FILE)
            print("üîÑ Cach√© de duplicados eliminado, se forzar√° verificaci√≥n")
    except Exception as e:
        print(f"Error eliminando cach√©: {e}")
